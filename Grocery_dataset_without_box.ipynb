{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import seaborn as sns\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SpatialGatingUnit(nn.Module):\n",
    "\n",
    "  def __init__(self, d_ffn, seq_len):\n",
    "    super(SpatialGatingUnit, self).__init__()\n",
    "\n",
    "    self.normalization = nn.LayerNorm(d_ffn // 2)\n",
    "    self.spatial_projection = nn.Linear(seq_len, seq_len)\n",
    "    # weights are initialized as close to zero and biases as one\n",
    "    weights = torch.empty((seq_len, seq_len))\n",
    "    nn.init.xavier_uniform_(weights)\n",
    "    weights *= 0.001\n",
    "    nn.init.ones_(self.spatial_projection.bias)\n",
    "\n",
    "\n",
    "  def forward(self, x):\n",
    "    u, v = x.chunk(2, dim=-1) # split x into two equal parts u and v along the channel axis\n",
    "    v = self.normalization(v) # perform layer normalization to v\n",
    "    v = v.permute(0, 2, 1) # change the channel with the spatial dimension for v\n",
    "    v = self.spatial_projection(v) # perform spatial projection\n",
    "    v = v.permute(0, 2, 1) # change the channel with the spatial dimension back to normal\n",
    "    return u * v # return the product of the element-wise multiplicated tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class definition of an gMLP block\n",
    "class gMLPBlock(nn.Module):\n",
    "\n",
    "  def __init__(self, d_model, d_ffn, seq_len, dropout_prob):\n",
    "    super(gMLPBlock, self).__init__()\n",
    "\n",
    "    self.normalization = nn.LayerNorm(d_model)\n",
    "    self.projection = nn.Linear(d_model, d_ffn)\n",
    "    self.activation = nn.GELU()\n",
    "    self.spatial_gating_unit = SpatialGatingUnit(d_ffn, seq_len)\n",
    "    self.projection2 = nn.Linear(d_ffn // 2, d_model)\n",
    "    self.dist = torch.distributions.bernoulli.Bernoulli(torch.Tensor([dropout_prob]))\n",
    "\n",
    "  def forward(self, x):\n",
    "    if self.training and torch.equal(self.dist.sample(), torch.zeros(1)):\n",
    "      return x # if network is training perform dropout with the given probability\n",
    "    shortcut = x # save copy of x for the shortcut\n",
    "    x = self.normalization(x) # perform normalization\n",
    "    x = self.projection(x) # perform projection from d_model to d_ffn along channels\n",
    "    x = self.activation(x) # perform gelu activation\n",
    "    x = self.spatial_gating_unit(x) # perform spatial gating unit\n",
    "    x = self.projection2(x) # peform projection from d_ffn/2 to d_model along channels\n",
    "    return x + shortcut # add shortcut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class definition of the gMLP model\n",
    "class gMLP(nn.Module):\n",
    "\n",
    "  def __init__(self, d_model, d_ffn, seq_len, lx, dropout_probs):\n",
    "    super(gMLP, self).__init__()\n",
    "\n",
    "    self.dropout_probs = torch.linspace(dropout_probs[0], dropout_probs[1], lx)\n",
    "    self.blocks = nn.Sequential(*[gMLPBlock(d_model, d_ffn, seq_len, dropout_prob) for dropout_prob in self.dropout_probs])\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.blocks(x) # perform lx sequential blocks of gmlp\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class gMLPImage(nn.Module):\n",
    "\n",
    "  def __init__(self, d_model, d_ffn, lx, patch_size, image_size, channels, classes, dropout_probs):\n",
    "    super(gMLPImage, self).__init__()\n",
    "    self.seq_len = (image_size // patch_size) ** 2\n",
    "    self.patch_embedding = nn.Conv2d(channels, d_model, kernel_size=patch_size, stride=patch_size)\n",
    "    self.gmlp = gMLP(d_model, d_ffn, self.seq_len, lx, dropout_probs)\n",
    "    self.output = nn.Linear(d_model, classes)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.patch_embedding(x) # do the patch embedding via a 2d conv\n",
    "    x = x.permute(0, 2, 3, 1)  # rearrange dimensions to (batch_size, height, width, channels)\n",
    "    x = x.contiguous().view(x.size(0), -1, x.size(-1))  # flattening into a single dimension of shape (batch_size, height*width, channels)\n",
    "    x = self.gmlp(x) # perform gmlp\n",
    "    x = x.mean(1) # perform global average pooling\n",
    "    x = self.output(x) # perform projection onto the desired number of output classes\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1                  # number of epochs to complete\n",
    "d_model = 220               # d_model\n",
    "d_ffn = 900                 # d_ffn\n",
    "lx = 6                      # number of blocks to be sequentially executed\n",
    "patch_size = 2              # patch size for patch embedding convolution\n",
    "image_size = 244             # size of the input images (must be square)\n",
    "classes = 10                # number of output classes\n",
    "channels = 3                # number of input channels (in our case rgb)\n",
    "dropout_probs = [0.9, 0.9]  # first and last value of droput probabilities that are used to created a linspace with a dropout prob for each block\n",
    "batch_size = 64             # batch size for the gradient descent\n",
    "eval_ratio = 0.2            # ratio of dataset used for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test dataset\n",
    "def evaluate_model(net, loader):\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm.tqdm(loader, desc=\"Evaluation\"):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "    accuracy = 100 * correct / total\n",
    "    precision = precision_score(all_labels, all_predictions, average='micro')\n",
    "    recall = recall_score(all_labels, all_predictions, average='micro')\n",
    "    conf_matrix = confusion_matrix(all_labels, all_predictions)\n",
    "    return accuracy, precision, recall, conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(preds, y):\n",
    "    preds = preds.argmax(dim=1, keepdim=True)\n",
    "    correct = preds.squeeze(1).eq(y)\n",
    "    acc = correct.sum() / torch.FloatTensor([y.shape[0]]).to(device)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def loop_vm(net, loader, opt, is_train):\n",
    "    net.train(is_train)\n",
    "    losses = []\n",
    "    accs = []\n",
    "    pbar = tqdm.tqdm(loader, total=len(loader))\n",
    "    for x, y in pbar:\n",
    "        x = x.to(device) \n",
    "        y = y.to(device)\n",
    "        \n",
    "        with torch.set_grad_enabled(is_train):\n",
    "            preds = net(x)\n",
    "            loss = loss_fn(preds, y)\n",
    "            acc = get_accuracy(preds, y)\n",
    "            losses.append(loss.item())\n",
    "            accs.append(acc.item())\n",
    "        if is_train:\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        if is_train:\n",
    "          pbar.set_description(f'Training  : Epoch: {epoch+1} Loss: {np.mean(losses):.4f} Acc: {np.mean(accs):.4f}')\n",
    "        else:\n",
    "          pbar.set_description(f'Validation: Epoch: {epoch+1} Loss: {np.mean(losses):.4f} Acc: {np.mean(accs):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmlp = gMLPImage(d_model = d_model,\n",
    "                 d_ffn = d_ffn,\n",
    "                 lx = lx,\n",
    "                 patch_size = patch_size,\n",
    "                 image_size = image_size,\n",
    "                 channels = channels,\n",
    "                 classes = classes,\n",
    "                 dropout_probs = dropout_probs\n",
    "                 ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms, datasets\n",
    "T = transforms.Compose([transforms.Resize((image_size, image_size)),transforms.ToTensor()])\n",
    "\n",
    "train = datasets.ImageFolder('./GroceryStoreDataset-master/dataset/train/Fruit', transform=T)\n",
    "test = datasets.ImageFolder('./GroceryStoreDataset-master/dataset/test/Fruit', transform=T)\n",
    "val = datasets.ImageFolder('./GroceryStoreDataset-master/dataset/val/Fruit', transform=T)\n",
    "\n",
    "class_names =train.classes\n",
    "\n",
    "train_loader = DataLoader(train, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "test_loader = DataLoader(test, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "val_loader = DataLoader(val, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/18 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "opt = torch.optim.Adam(gmlp.parameters()) # set optimizer to the adam optimizer\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loop_vm(gmlp, train_loader, opt, True)\n",
    "    loop_vm(gmlp, val_loader, opt, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation:   0%|          | 0/18 [00:14<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "test_accuracy, test_precision, test_recall, conf_matrix = evaluate_model(gmlp, test_loader)\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}%\\nTest Precision: {test_precision * 100:.2f}%\\nTest Recall: {test_recall * 100:.2f}%\")\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d',xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
